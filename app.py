import streamlit as st
import pandas as pd
from statsmodels.tsa.holtwinters import ExponentialSmoothing
import plotly.express as px
from st_aggrid import AgGrid
from googleapiclient.discovery import build

# YouTube API í‚¤
YOUTUBE_API_KEY = "AIzaSyAHjsvQRyMnFVsjbFgj02Ws5dXMgnTOD0M"

# YouTube API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
youtube = build("youtube", "v3", developerKey=YOUTUBE_API_KEY)

# YouTube ë°ì´í„° ê°€ì ¸ì˜¤ê¸° í•¨ìˆ˜
def fetch_youtube_data(keyword, max_results=10):
    request = youtube.search().list(
        part="snippet",
        q=keyword,
        type="video",
        maxResults=max_results
    )
    response = request.execute()

    # ë™ì˜ìƒ ID ì¶”ì¶œ
    video_ids = [item["id"]["videoId"] for item in response["items"]]
    stats_request = youtube.videos().list(
        part="statistics",
        id=",".join(video_ids)
    )
    stats_response = stats_request.execute()
    stats_dict = {item["id"]: item["statistics"].get("viewCount", "0") for item in stats_response["items"]}

    data = [
        {
            "ê²Œì‹œì¼": item["snippet"]["publishedAt"],
            "ì±„ë„ëª…": item["snippet"]["channelTitle"],
            "êµ¬ë…ììˆ˜": stats_dict.get(item["id"]["videoId"], "0"),
            "ì œëª©": item["snippet"]["title"],
            "ë§í¬": f"https://www.youtube.com/watch?v={item['id']['videoId']}",
            "ì„¤ëª…": item["snippet"]["description"],
        }
        for item in response.get("items", [])
    ]
    return data

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë§¤ì¶œ ì˜ˆì¸¡ ë° YouTube ë°ì´í„° ëŒ€ì‹œë³´ë“œ",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ì œëª© ë° ì„¤ëª…
st.title("ğŸ“Š ë§¤ì¶œ ì˜ˆì¸¡ ë° YouTube ë°ì´í„° ëŒ€ì‹œë³´ë“œ")
st.markdown("""
    ì´ ëŒ€ì‹œë³´ë“œëŠ” ë§¤ì¶œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì˜ˆì¸¡í•˜ë©°, YouTube ë°ì´í„°ë¥¼ ì—°ë™í•˜ì—¬ ë‹¤ì–‘í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
""")

# íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ë§¤ì¶œ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (Excel)", type=["xlsx", "xls"])

if uploaded_file:
    # ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
    @st.cache_data
    def load_data(file):
        df = pd.read_excel(file)
        df["ì§„í–‰ ë‚ ì§œ"] = pd.to_datetime(df["ì§„í–‰ ë‚ ì§œ"], format='%Y%m%d')  # ë‚ ì§œ í˜•ì‹ ë³€í™˜
        return df

    df = load_data(uploaded_file)

    # ë°ì´í„° í•„í„°ë§ UI
    with st.sidebar:
        st.header("ë§¤ì¶œ ë°ì´í„° í•„í„° ì„¤ì •")
        grades = st.multiselect("í–‰ì‚¬ ë“±ê¸‰ ì„ íƒ", options=df["í–‰ì‚¬ë“±ê¸‰"].dropna().unique().tolist())
        malls = st.multiselect("ìš´ì˜ëª° ì„ íƒ", options=df["ìš´ì˜ëª°"].dropna().unique().tolist())
        brands = st.multiselect("ë¸Œëœë“œëª… ì„ íƒ", options=df["ë¸Œëœë“œëª…"].dropna().unique().tolist())
        categories = st.multiselect("ì¹´í…Œê³ ë¦¬ ì„ íƒ", options=df["ì¹´í…Œê³ ë¦¬"].dropna().unique().tolist())
        sub_categories = st.multiselect("ì„¸ë¶„ë¥˜ ì„ íƒ", options=df["ì„¸ë¶„ë¥˜"].dropna().unique().tolist())

        min_price, max_price = st.slider(
            "íŒë§¤ê°€ ë²”ìœ„",
            min_value=int(df["íŒë§¤ê°€"].min()),
            max_value=int(df["íŒë§¤ê°€"].max()),
            value=(int(df["íŒë§¤ê°€"].min()), int(df["íŒë§¤ê°€"].max()))
        )

        min_sales, max_sales = st.slider(
            "ë§¤ì¶œ ë²”ìœ„",
            min_value=int(df["ë§¤ì¶œ"].min()),
            max_value=int(df["ë§¤ì¶œ"].max()),
            value=(int(df["ë§¤ì¶œ"].min()), int(df["ë§¤ì¶œ"].max()))
        )

        start_date, end_date = st.date_input(
            "ë‚ ì§œ ë²”ìœ„ ì„ íƒ",
            value=[df["ì§„í–‰ ë‚ ì§œ"].min(), df["ì§„í–‰ ë‚ ì§œ"].max()],
            min_value=df["ì§„í–‰ ë‚ ì§œ"].min(),
            max_value=df["ì§„í–‰ ë‚ ì§œ"].max()
        )

    # YouTube ë°ì´í„° í•„í„° ì„¤ì •
    with st.sidebar:
        st.header("YouTube ë°ì´í„° í•„í„° ì„¤ì •")
        youtube_keyword = st.text_input("ğŸ” YouTube ê²€ìƒ‰ í‚¤ì›Œë“œ ì…ë ¥", placeholder="ì˜ˆ: ì‹ ì œí’ˆ, ë§¤ì¶œ")
        max_results = st.slider("YouTube ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜", min_value=1, max_value=50, value=10)

    # ë§¤ì¶œ ë°ì´í„° í•„í„°ë§
    filtered_data = df.copy()
    if grades:
        filtered_data = filtered_data[filtered_data["í–‰ì‚¬ë“±ê¸‰"].isin(grades)]
    if malls:
        filtered_data = filtered_data[filtered_data["ìš´ì˜ëª°"].isin(malls)]
    if brands:
        filtered_data = filtered_data[filtered_data["ë¸Œëœë“œëª…"].isin(brands)]
    if categories:
        filtered_data = filtered_data[filtered_data["ì¹´í…Œê³ ë¦¬"].isin(categories)]
    if sub_categories:
        filtered_data = filtered_data[filtered_data["ì„¸ë¶„ë¥˜"].isin(sub_categories)]

    filtered_data = filtered_data[
        (filtered_data["íŒë§¤ê°€"] >= min_price) &
        (filtered_data["íŒë§¤ê°€"] <= max_price) &
        (filtered_data["ë§¤ì¶œ"] >= min_sales) &
        (filtered_data["ë§¤ì¶œ"] <= max_sales)
    ]

    filtered_data = filtered_data[
        (filtered_data["ì§„í–‰ ë‚ ì§œ"] >= pd.Timestamp(start_date)) &
        (filtered_data["ì§„í–‰ ë‚ ì§œ"] <= pd.Timestamp(end_date))
    ]

    # ì£¼ìš” ì§€í‘œ ì¶œë ¥
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric(label="ì´ ë§¤ì¶œ", value=f"{filtered_data['ë§¤ì¶œ'].sum():,}ì›")
    with col2:
        st.metric(label="í‰ê·  íŒë§¤ê°€", value=f"{filtered_data['íŒë§¤ê°€'].mean():,.2f}ì›")
    with col3:
        st.metric(label="ë°ì´í„° ê°œìˆ˜", value=len(filtered_data))

    # ë°ì´í„° í…Œì´ë¸”
    st.subheader("ğŸ“‹ í•„í„°ë§ëœ ë§¤ì¶œ ë°ì´í„°")
    AgGrid(filtered_data, height=300, theme="streamlit")

    # ë§¤ì¶œ ì‹œê°í™” ë° ì˜ˆì¸¡
    st.subheader("ğŸ“ˆ ë§¤ì¶œ ì¶”ì´ ì‹œê°í™”")
    monthly_sales = filtered_data.copy()
    monthly_sales["ì›”"] = monthly_sales["ì§„í–‰ ë‚ ì§œ"].dt.to_period("M")
    monthly_sales = monthly_sales.groupby("ì›”")["ë§¤ì¶œ"].sum().reset_index()
    monthly_sales["ì›”"] = monthly_sales["ì›”"].dt.to_timestamp()

    if not monthly_sales.empty:
        fig = px.line(monthly_sales, x="ì›”", y="ë§¤ì¶œ", title="ì›”ë³„ ë§¤ì¶œ ì¶”ì´", labels={"ë§¤ì¶œ": "ë§¤ì¶œ(ì›)", "ì›”": "ë‚ ì§œ"})
        st.plotly_chart(fig, use_container_width=True)

        # ë§¤ì¶œ ì˜ˆì¸¡
        st.subheader("ğŸ”® ë§¤ì¶œ ì˜ˆì¸¡")
        if len(monthly_sales) >= 2:
            periods_to_forecast = st.slider("ì˜ˆì¸¡í•  ê°œì›” ìˆ˜", 1, 24, 12)
            try:
                model = ExponentialSmoothing(
                    monthly_sales["ë§¤ì¶œ"],
                    trend="add",
                    seasonal="add" if len(monthly_sales) >= 24 else None,
                    seasonal_periods=12 if len(monthly_sales) >= 24 else None,
                )
                model_fit = model.fit()
                forecast = model_fit.forecast(periods_to_forecast)

                forecast_dates = pd.date_range(
                    start=monthly_sales["ì›”"].iloc[-1] + pd.offsets.MonthBegin(),
                    periods=periods_to_forecast,
                    freq="MS"
                )
                forecast_df = pd.DataFrame({"ì˜ˆì¸¡ ë‚ ì§œ": forecast_dates, "ì˜ˆìƒ ë§¤ì¶œ": forecast})

                # ì˜ˆì¸¡ ê·¸ë˜í”„
                forecast_fig = px.line(
                    forecast_df, x="ì˜ˆì¸¡ ë‚ ì§œ", y="ì˜ˆìƒ ë§¤ì¶œ", title="ì˜ˆìƒ ë§¤ì¶œ ì¶”ì´", labels={"ì˜ˆìƒ ë§¤ì¶œ": "ë§¤ì¶œ(ì›)", "ì˜ˆì¸¡ ë‚ ì§œ": "ë‚ ì§œ"}
                )
                forecast_fig.add_scatter(x=monthly_sales["ì›”"], y=monthly_sales["ë§¤ì¶œ"], mode="lines", name="ì‹¤ì œ ë§¤ì¶œ")
                st.plotly_chart(forecast_fig, use_container_width=True)

                # ì˜ˆì¸¡ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
                st.download_button(
                    label="ğŸ“¥ ì˜ˆì¸¡ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
                    data=forecast_df.to_csv(index=False).encode("utf-8"),
                    file_name="forecast.csv",
                    mime="text/csv"
                )
            except Exception as e:
                st.error(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        else:
            st.warning("ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ë§¤ì¶œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # YouTube ë°ì´í„° ê²€ìƒ‰
    if youtube_keyword:
        st.subheader(f"ğŸ” YouTube ê²€ìƒ‰ ê²°ê³¼ - '{youtube_keyword}'")
        youtube_data = fetch_youtube_data(youtube_keyword, max_results)
        youtube_df = pd.DataFrame(youtube_data)

        # ë§í¬ë¥¼ í´ë¦­ ê°€ëŠ¥í•œ HTML í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        youtube_df["ë§í¬"] = youtube_df["ë§í¬"].apply(
            lambda x: f'<a href="{x}" target="_blank">ë™ì˜ìƒ ë³´ê¸°</a>'
        )

        # ë°ì´í„° í‘œì‹œ (Streamlit HTML ë Œë”ë§ ì‚¬ìš©)
        st.write(
            youtube_df[["ê²Œì‹œì¼", "ì±„ë„ëª…", "êµ¬ë…ììˆ˜", "ì œëª©", "ë§í¬", "ì„¤ëª…"]].to_html(escape=False, index=False),
            unsafe_allow_html=True
        )

        # YouTube ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        st.download_button(
            label="ğŸ“¥ YouTube ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
            data=youtube_df.to_csv(index=False).encode("utf-8"),
            file_name=f"{youtube_keyword}_youtube_results.csv",
            mime="text/csv"
        )

else:
    st.info("ğŸ“¤ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ YouTube ê²€ìƒ‰ì„ ì‹œì‘í•˜ì„¸ìš”.")
